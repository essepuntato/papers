<!DOCTYPE html>
<!-- 
Automating Semantic Publishing
by Silvio Peroni

This work is licensed under a Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/).
You are free to:
* Share - copy and redistribute the material in any medium or format
* Adapt - remix, transform, and build upon the material
for any purpose, even commercially.

The licensor cannot revoke these freedoms as long as you follow the license terms.

Under the following terms:
* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.
-->
<html xmlns="http://www.w3.org/1999/xhtml" 
      prefix="
         amo: http://www.essepuntato.it/2011/02/argumentmodel/
         biro: http://purl.org/spar/biro/
         c4o: http://purl.org/spar/c4o/
         cito: http://purl.org/spar/cito/
         dcterms: http://purl.org/dc/terms/
         deo: http://purl.org/spar/deo/
         doco: http://purl.org/spar/doco/
         fabio: http://purl.org/spar/fabio/
         frapo: http://purl.org/cerif/frapo/
         frbr: http://purl.org/vocab/frbr/core#
         po: http://www.essepuntato.it/2008/12/pattern#
         prism: http://prismstandard.org/namespaces/basic/2.0/
         schema: http://schema.org/">
   <head typeof="fabio:JournalArticle">
      <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
      <meta name="viewport" content="width=device-width, initial-scale=1"/>
      <link rel="stylesheet" href="../css/bootstrap.min.css"/>
      <link rel="stylesheet" href="../css/rash.css"/>
      <script src="../js/jquery.min.js"> </script>
      <script src="../js/bootstrap.min.js"> </script>
      <script src="../js/rash.js"> </script>
      <title lang="en" property="dcterms:title">Automating Semantic Publishing</title>
      <meta about="#dasplab"
            property="schema:name"
            content="Digital And Semantic Publishing Laboratory, Department of Computer Science and Engineering, University of Bologna, Bologna, Italy"/>
      <meta about="http://orcid.org/0000-0003-0530-4305"
            name="dc.creator"
            rel="dcterms:creator"
            property="schema:name"
            content="Silvio Peroni"/>
      <meta about="http://orcid.org/0000-0003-0530-4305"
            property="schema:email"
            content="silvio.peroni@unibo.it"/>
      <link about="http://orcid.org/0000-0003-0530-4305"
            property="schema:affiliation"
            href="#dasplab"/>
      <meta about="http://orcid.org/0000-0003-0530-4305"
            property="frapo:hasORCID"
            content="0000-0003-0530-4305"/>
      <meta lang="en" property="prism:keyword" content="Semantic Publishing"/>
      <meta lang="en" property="prism:keyword" content="Compositional and Iterative Semantic Enhancement"/>
      <meta lang="en" property="prism:keyword" content="CISE"/>
      <meta lang="en" property="prism:keyword" content="Principle of Compositionality"/>
      <meta lang="en" property="prism:keyword" content="Downward Causation"/>
      <meta lang="en" property="prism:keyword" content="Syntactic Containment"/>
      <meta lang="en" property="prism:keyword" content="Structural Patterns"/>
      <meta lang="en" property="prism:keyword" content="Structural Semantics"/>
      <meta lang="en" property="prism:keyword" content="Rhetorical Components"/>
      <script type="text/turtle">
         <![CDATA[
            @prefix fabio: <http://purl.org/spar/fabio/> .
            @prefix dcterms: <http://purl.org/dc/terms/> .
            @prefix pro: <http://purl.org/spar/pro/> .
            @prefix scoro: <http://purl.org/spar/scoro/> .
            @prefix foaf: <http://xmlns.com/foaf/0.1/> .
            
            <> a fabio:JournalArticle ;
               dcterms:creator <http://orcid.org/0000-0003-0530-4305> .
            <http://orcid.org/0000-0003-0530-4305> a foaf:Person ;
               pro:holdsRoleInTime <#author> , <#affiliation> .
            
            <#author> a pro:RoleInTime ;
               pro:withRole pro:author ;
               pro:relatesToDocument <> .
            
            <#affiliation> a pro:RoleInTime ;
               pro:withRole scoro:affiliate ;
               pro:relatesToOrganization <#dasplab> .
            
            <#dasplab> a foaf:Organization ;
               foaf:homepage <http://dasplab.cs.unibo.it> .
         ]]>
      </script>
   </head>
   
   <body rel="frbr:part" lang="en">
      <section id="abstract" about="#abstract" typeof="doco:Abstract doco:Section" role="doc-abstract">
         <h1 property="dcterms:title">Abstract</h1>
         <p about="" property="dcterms:abstract">Semantic Publishing involves the use of Web and Semantic Web technologies and standards for the semantic enhancement of a scholarly work so as to improve its discoverability, interactivity, openness and (re-)usability for both humans and machines. Recently, people have suggested that the semantic enhancements of a scholarly work should be undertaken by the authors of that scholarly work, and should be considered as integral parts of the contribution subjected to peer review. However, this requires that the authors should spend additional time and effort adding such semantic annotations, time that they usually do not have available. Thus, the most pragmatic way to facilitate this additional task is to use automated services that create the semantic annotation of authors' scholarly articles by parsing the content that they have already written, thus reducing the additional time required of the authors to that for checking and validating these semantic annotations. In this article, I propose a generic approach called <em>compositional and iterative semantic enhancement</em> (CISE) that enables the automatic enhancement of scholarly papers with additional semantic annotations in a way that is independent of the markup used for storing scholarly articles and the natural language used for writing their content.</p>
         <p about=""><strong>License:</strong> <a rel="dcterms:license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
         <p about=""><strong>Notes:</strong> postprint accepted to <a rel="frbr:partOf" href="https://datasciencehub.net/">Data Science</a>.</p>
         <p about=""><strong>This version:</strong> <a rel="fabio:hasRepresentation" href="https://w3id.org/people/essepuntato/papers/cise-datascience2017/2017-09-25.html">https://w3id.org/people/essepuntato/papers/cise-datascience2017/2017-09-25.html</a></p>
         <p about=""><strong>Last version:</strong> <a rel="fabio:hasRepresentation" href="https://w3id.org/people/essepuntato/papers/cise-datascience2017.html">https://w3id.org/people/essepuntato/papers/cise-datascience2017.html</a></p>
         <p about=""><strong>RDF statements:</strong> <a rel="frbr:relatedEndeavour" href="https://w3id.org/people/essepuntato/papers/cise-datascience2017.ttl">https://w3id.org/people/essepuntato/papers/cise-datascience2017.ttl</a></p>
      </section>
      <section id="introduction" about="#introduction" typeof="deo:Introduction doco:Section">
         <h1 property="dcterms:title">Print, Digital, and Semantic Publishing</h1>
         <p>The scholarly communication domain has been involved in several revolutions concerning the way scientific knowledge has been shared in the past 300 years. <a rel="cito:linksTo" href="https://en.wikipedia.org/wiki/Johannes_Gutenberg">Gutenberg's introduction of the print (around 1450)</a> together with the creation of formally-defined groups of scholars (e.g. <a rel="cito:linksTo" href="https://en.wikipedia.org/wiki/Royal_Society">the Royal Society founded in 1660</a>) have permitted research works to be shared according to a well-known medium, i.e. printed volumes of scholarly journals. Notable examples of this era are <a rel="cito:linksTo" href="https://en.wikipedia.org/wiki/Philosophical_Transactions_of_the_Royal_Society">Philosophical Transactions</a> published by the Royal Society (first issued in 1776, and <a rel="cito:linksTo" href="http://rstl.royalsocietypublishing.org/">still in publication</a>) and <a rel="cito:linksTo" href="https://en.wikipedia.org/wiki/The_Lancet">The Lancet</a> (first issued in 1823, and <a rel="cito:linksTo" href="http://www.thelancet.com/">currently published by Elsevier</a>). The basic form of the scientific paper remained unchanged until the introduction of the <a rel="cito:linksTo" href="https://en.wikipedia.org/wiki/Internet">Internet</a> (considering <a rel="cito:linksTo" href="https://en.wikipedia.org/wiki/ARPANET">ARPANET</a> as its first implementation around 1960), which enabled research results to be rapidly communicated by means of e-mails. However, it was advent of the <a rel="cito:linksTo" href="https://en.wikipedia.org/wiki/World_Wide_Web">World Wide Web</a> (WWW) in 1989 that made possible the explosion of the <a rel="cito:linksTo" href="https://en.wikipedia.org/wiki/Electronic_publishing">Digital Publishing</a>, namely the use of digital formats for the routine publication and distribution of scholarly works. In the last twenty years, the availability of new Web technologies and the reduction of digital storage have resulted in an incredible growth in the availability of scholarly material online, and in an accompanying acceleration of the publishing workflow. However, only with the subsequent advent of one specific set of Web technologies, namely Semantic Web technologies <span rel="frbr:part"><a id="bernerslee2001-p1" about="#bernerslee2001-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#bernerslee2001"> </a></span>, have we started to talk about <em>Semantic Publishing</em>.</p>
         <p>Within the scholarly domain, Semantic Publishing concerns the use of Web and Semantic Web technologies and standards for enhancing a scholarly work semantically (by means of plain RDF statements <span rel="frbr:part"><a id="cyganiak2014-p1" about="#cyganiak2014-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#cyganiak2014"> </a></span>, nano-publications <span rel="frbr:part"><a id="groth2010-p1" about="#groth2010-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#groth2010"> </a></span>, etc.) so as to improve its discoverability, interactivity, openness and (re-)usability for both humans and machines <span rel="frbr:part"><a id="shotton2009-p1" about="#shotton2009-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#shotton2009"> </a></span>. The assumptions of openness implicit in Semantic Publishing have been explicitly adopted for the publication of research data by the FAIR (Findable, Accessible, Interoperable, Re-usable) data principles <span rel="frbr:part"><a id="wilkinson2016-p1" about="#wilkinson2016-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#wilkinson2016"> </a></span>. Early examples of the semantic enrichment of scholarly works involved the use of manual (e.g. <span rel="frbr:part"><a id="shotton2009_2-p1" about="#shotton2009_2-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#shotton2009_2"> </a></span>) or (semi-)automatic post-publication processes (e.g. <span rel="frbr:part"><a id="bagnacani2014-p1" about="#bagnacani2014-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#bagnacani2014"> </a></span>) by people other than the original authors of such works.</p>
         <p>The misalignment between those who authored the original work and those who added semantic annotations to it is the focal point for discussion by the editors-in-chief of this journal in this introductory issue. Their point is that, following the early experimentation with Semantic Publishing, we should now start to push for and support what they call <em>Genuine Semantic Publishing</em>. This <em>genuineness</em> basically refers to the fact that the semantic enhancement of a scholarly work should be undertaken by the authors of that scholarly work at the time of writing. According to this perspective, the semantic annotations included within the scholarly work includes should be considered as proper part of the contribution and treated as such, including being subjected to proper peer review.</p>
         <p>While the Genuine Semantic Publishing is, indeed, a desirable goal, it requires specific incentives to induce the authors to spend additional time creating the semantic enrichments to their articles, over and above that required to create the textual content. In recent experiments, my colleagues and I have undertaken in the context of the SAVE-SD workshops, described in <span rel="frbr:part"><a id="peroni2016-p1" about="#peroni2016-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#peroni2016"> </a></span>, the clear trend is that, with the exception of the few individuals who <em>believe</em> in the Semantic Publishing as a public good, generally only a very low number of semantic statements are specified by the authors, even if we made available incentives or prizes for people who submit their scholarly papers in HTML+RDF format. The number of semantic statements in each of the papers presented during SAVE-SD workshops ranged from 24 to 903, with a median value of 46 (25th percentile 34, 75th percentile 175). The possible reasons for this behaviour, as identified by the study, included the lack of appropriate support, in the form of graphical user interfaces, that would facilitate the annotation of scholarly works with semantic data.</p>
         <p>However, I do not think that this is the principal reason that prevents the majority of authors from enhancing their papers with semantic annotations. I firmly believe that the main bottleneck preventing concrete adoption of Genuine Semantic Publishing principles is <em>the authors' lack of available time</em>. While interfaces may simplify the creation of semantic annotations, an author is still required to spend additional time and effort for this task, and often she does not have that time available. Thus, the most pragmatic mathod of encouraging authors to undertake this additional step is to provide services that do it for them in an <em>automatic fashion</em> by parsing the content that the authors have already written, thereby reducing the author's task to one of checking these automated proposals for semantic annotations and then adding them to the document with a few clicks.</p>
         <p>In recent years, several tools have been developed for the automatic annotation of scholarly texts according to one or more particular dimensions, e.g. by considering documents that are available in specific document formats – e.g. the <a rel="cito:linksTo" href="https://github.com/essepuntato/rash/tree/master/tools/spar-xtractor">SPAR Extractor Suite</a> developed for the <a rel="cito:linksTo" href="https://github.com/essepuntato/rash">RASH format</a> 
            <span rel="frbr:part"><a id="peroni2016-p2" about="#peroni2016-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#peroni2016"> </a></span> – or that are written in a particular language such as English – e.g. <a rel="cito:linksTo" href="http://wit.istc.cnr.it/stlab-tools/fred">FRED</a><a href="#fred-languages"></a> 
            <span rel="frbr:part"><a id="gangemi2017-p1" about="#gangemi2017-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#gangemi2017"> </a></span>. However, these tools are typically tied to certain requirements – in the aforementioned cases, the use of a specific <em>markup</em> for organising the document content and of a particular <em>language</em> for writing its text – that prevent their adoption in broader contexts. I wonder if we can propose an alternative approach that allows a machine to infer some of the semantic annotations for scholarly articles <strong>without considering</strong> the particular markup language used nor authoring language used.</p>
         <p>This is a Document Engineering issue, rather than a pure Computational Linguistics one. Thus, an important aspect to investigate is whether one can use the syntactic organisation of the text (i.e. the way the various parts of the article are related to each other) to enable the meaningful automatic semantic annotation of the article. It is possible to abstract this view into a more generic research question: <q>Can the purely syntactic organisation of the various parts of a scholarly article convey something about its semantic and rhetorical representation, and to what extent?</q></p>
         <p>While I do not have a definite answer to that question, existing theories – such as the <em>principle of compositionality</em> <span rel="frbr:part"><a id="pelletier1994-p1" about="#pelletier1994-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#pelletier1994"></a></span> and the <em>downward causation</em> <span rel="frbr:part"><a id="campbell1974-p1" about="#campbell1974-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#campbell1974"></a></span>, which I discuss in more detail in <a href="#pathway"></a> – seem to suggest that, under certain conditions, they can provide theoretical foundations for for that question. Inspired by the way these theories have been used in several domains, I have developed a generic approach called <em>compositional and iterative semantic enhancement</em>, a.k.a. <em>CISE</em> (pronounced like <em>size</em>), that <span about="#main-argument-claim" typeof="amo:Claim" property="dcterms:description">enables the automatic enhancement of scholarly articles solely by consideration of the containment between their components</span>. This requires an iterative process in which each step provides additional semantic annotations to article components by applying specific rules to the enhancements generated by the previous steps.</p>
         <p>In order to prove the applicability of CISE, and thus to provide a partial answer to the aforementioned research question, my colleagues and I have implemented and run some CISE-based algorithms, which enable us to annotate various components of scholarly articles with information about their syntactic and semantic structures and basic rhetorical purposes. To do this, we use a collection of ontologies that form a kind of hierarchy that can be used to annotate different aspects a publication – i.e. syntactic containment, syntactic structure, structural semantics, and rhetorical components – with semantic statements. The <span about="#main-argument-warrant" typeof="amo:Warrant" property="dcterms:description" rel="amo:leadsTo" resource="#main-argument-claim">outcomes of using these CISE-based algorithms are encouraging, and seem to suggest the feasibility of the whole approach</span>.</p>
         <p>The rest of the paper is organised as follows. In <a href="#relatedworks"> </a> I introduce some of the most important research works on this topic. In <a href="#pathway"> </a> I introduce the foundational theories that have been used to derive the approach for automating the enhancement of scholarly articles. In <a href="#cise"> </a> I introduce CISE by describing the main conditions needed for running it and by explaining the algorithm defining the approach. In <a href="#evidence"> </a> I briefly discuss the results of implementing CISE on a corpus of scholarly articles stored in XML formats. In <a href="#limitations"></a> I present some limitations of the approach, as well as future directions for my research on this subject. Finally, in <a href="#conclusions"> </a> I conclude the paper, reprising the research question mentioned above.</p>
      </section>
      
      <section id="relatedworks" about="#relatedworks" typeof="deo:RelatedWork doco:Section">
         <h1 property="dcterms:title">Related works</h1>
         <p>Past Document Engineering works that have proposed algorithms for the characterization and identification of particular structural behaviours of various parts of text documents. For instance, in <span rel="frbr:part"><a id="tannier2005-p1" about="#tannier2005-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#tannier2005"></a></span>, Tannier et al. present an algorithm based on Natural Language Processing (NLP) tools for assigning each element of an XML document to one of three categories. These categories are <em>hard tag</em> (i.e. those elements that interrupt the linearity of a text, such as paragraphs and sections), <em>soft tag</em> (i.e. the elements that identify significant text fragments that do not break the text flow, such as emphasis and links), and <em>jump tag</em> (i.e. those elements that are detached from the surrounding text, such as footnotes and comments).</p>
         <p>In another work <span rel="frbr:part"><a id="zou2007-p1" about="#zou2007-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#zou2007"></a></span>, Zou et al. propose a categorization of HTML elements based on two classes: <em>inline</em> (i.e. those that do not provide horizontal breaks in the visualisation of an HTML document) and <em>line-break</em> tags (i.e. the opposite of the inline class). They also have developed an algorithm that uses this categorization and a Hidden Markov Model for identifying the structural roles (title, author, affiliation, abstract, etc.) of textual fragments – using a corpus of medical journal articles stored in HTML to provide examples.</p>
         <p>The approach proposed by Koh et al. <span rel="frbr:part"><a id="koh2007-p1" about="#koh2007-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#koh2007"></a></span> is to identify junk structures in HTML documents, such as navigation menus, advertisements, and footers. In particular, their algorithm recognises recurring hierarchies of nested elements and allows one to exclude all the HTML markup that does not concern the actual content of the document.</p>
         <p>Other approaches based on the application of Optical Character Recognition (OCR) techniques to a corpus of PDF documents have also been proposed, with the goal of reconstructing the organisation of a document by marking up its most meaningful parts. For instance, in <span rel="frbr:part"><a id="kim2000-p1" about="#kim2000-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#kim2000"></a></span>, Kim et al. propose an approach based on the OCR recognition of article zones so as to label them with particular categories, such as affiliations, abstract, sections, titles and authors. Similarly, in <span rel="frbr:part"><a id="taghva2006-p1" about="#taghva2006-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#taghva2006"></a></span>, Taghva et al. use an OCR technique for reconstructing the logical structure of technical documents starting from the information about fonts and geometry of a scanned document.</p>
         <p>Several other works have introduced theories and algorithms for the identification of various characterizations of scholarly articles, such as entities cited in articles (e.g. <span rel="frbr:part"><a id="fink2010-p1" about="#fink2010-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#fink2010"></a></span>), rhetorical structures (e.g. <span rel="frbr:part"><a id="liakata2010-p1" about="#liakata2010-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#liakata2010"></a></span>), arguments (e.g. <span rel="frbr:part"><a id="sateli2015-p1" about="#sateli2015-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#sateli2015"></a></span>), and citation functions (e.g. <span rel="frbr:part"><a id="teufel2006-p1" about="#teufel2006-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#teufel2006"></a></span>, <span rel="frbr:part"><a id="diiorio2013_2-p1" about="#diiorio2013_2-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2013_2"></a></span> and <span rel="frbr:part"><a id="jha2017-p1" about="#jha2017-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#jha2017"></a></span>). In addition, models and ontologies have been proposed for creating and associating annotations to documents and their parts, e.g. <span rel="frbr:part"><a id="sanderson2017-p1" about="#sanderson2017-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#sanderson2017"></a></span>, <span rel="frbr:part"><a id="moreau2013-p1" about="#moreau2013-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#moreau2013"></a></span>, <span rel="frbr:part"><a id="comeau2013-p1" about="#comeau2013-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#comeau2013"></a></span>, and <span rel="frbr:part"><a id="livingston2013-p1" about="#livingston2013-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#livingston2013"></a></span>. </p>
         <p>These papers thus propose algorithms based on NLP tools, Machine Learning approaches, and OCR frameworks for annotating the various component parts of a document with specific categories. In contrast, the work I present in this article uses none of these techniques. Rather, it involves a pure Document Engineering analysis of the containment relations between the various document parts, without consideration of any aspect related to the language used to write the document or the markup language used to store it. CISE is thus compatible with and complementary to the aforementioned tools, and in principle each could be used to refine the results of the other. However, exploring these kinds of interactions is beyond the scope of this article.</p>
      </section>
      
      <section id="pathway" about="#pathway" typeof="deo:Materials deo:Methods doco:Section">
         <h1 property="dcterms:title">A pathway from syntax to semantics</h1>
         
         <p>The <em>principle of compositionality</em> states that the <q>meaning of an expression is a function of, and only of, the meanings of its parts together with the method by which those parts are combined</q> <span rel="frbr:part"><a id="pelletier1994-p2" about="#pelletier1994-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#pelletier1994"></a></span>. This definition is quite broad. In fact, it does not precisely define several aspects, such as what is a <em>meaning</em>, what is a <em>function</em>, and what is a <em>part</em> of an expression. Despite its vagueness, this principle has been used in works of several disciplines, such as:</p>
         <ul>
            <li><p>Linguistics, e.g. Richard Montague, in one of his seminal works <span rel="frbr:part"><a id="montague1970-p1" about="#montague1970-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#montague1970"> </a></span>, proposes an approach that allows the definition of a precise syntax of a natural language (such as English) by means of a set of syntactic categories that are mapped to their possible semantic representations expressed as mathematical formulas by means of explicit conversion rules. In particular, the way the syntactic categories are combined within the syntactic structure of a sentence is used to derive its meaning;</p></li>
            <li><p>Computer Science, e.g. the Curry-Howard isomorphism <span rel="frbr:part"><a id="howard1980-p1" about="#howard1980-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#howard1980"> </a></span>, which states that the proof system and the model of computation (such as the lambda calculus) are actually the same mathematical tool presented from two different perspectives. In this light, mathematical proofs can be written as runnable computer programs, and vice versa;</p></li>
            <li><p>Molecular Biology, e.g. the reductionist approach used by Crick <span rel="frbr:part"><a id="crick1966-p1" about="#crick1966-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#crick1966"></a></span>, among others, which claims that the behaviour of high-level functions of a larger biological system (e.g. an organism) can be explained by looking at the ways in which its low-level components (e.g. its genes) actually work.</p></li>
         </ul>
         <p>I propose that the same principle of compositionality can be used to infer high-level semantics from the low-level structural organisation of a scholarly article. The idea is to annotate the various parts of a scholarly article progressively according to diverse layers of annotations, from the lower syntactic layers to higher semantic layers<a href="#semantic-lenses"></a>. For instance, a possible stratification of such layers (from the most syntactic ones to the most semantic ones) is illustrated as follows:</p>
         <ol>
            <li>
               <p>syntactic containment, i.e. the dominance and containment relations <span rel="frbr:part"><a id="sperbergmcqueen2004-p1" about="#sperbergmcqueen2004-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#sperbergmcqueen2004"> </a></span> that exist between the various parts of scholarly articles;</p>
            </li>
            <li>
               <p>syntactic structures, i.e. the particular structural pattern (inline, block, etc.) of each part;</p>
            </li>
            <li>
               <p>structural semantics, i.e. the typical article structural types within articles, such as sections, paragraphs, tables, figures;</p>
            </li>
            <li>
               <p>rhetorical components, i.e. the functions that characterize each section, such as introduction, methods, material, data, results, conclusions;</p>
            </li>
            <li>
               <p>citation functions, i.e. the characterization of all inline citations (i.e. in-text reference pointers) with the inferred reason why the authors have made each citation <span rel="frbr:part"><a id="teufel2006-p2" about="#teufel2006-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#teufel2006"> </a></span>;</p>
            </li>
            <li>
               <p>argumentative organisation, i.e. the relations among the various parts of scholarly articles according to particular argumentative models such as Toulmin's <span rel="frbr:part"><a id="toulmin1958-p1" about="#toulmin1958-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#toulmin1958"> </a></span>;</p>
            </li>
            <li>
               <p>article categorization, i.e. the type, either in terms of publication venue (journal article, conference paper, etc.) or content (research paper, review, opinion, etc.), of each scholarly article;</p>
            </li>
            <li>
               <p>discipline clustering, i.e. the identification of the discipline(s) to which each article belongs to.</p>
            </li>
         </ol>
         <p>The graph on the left in <a href="#fig-layers"></a> shows a strict application of the principle of compositionality. While it may seem valid from an intuitive perspective, past studies (e.g. <span rel="frbr:part"><a id="noble2008-p1" about="#noble2008-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#noble2008"> </a></span><a href="#noble-thesis"></a>) have proved that the sole application of such principle could not guarantee successful recognition of all the possible interactions existing in a layered system, such as the one that defines the various kinds of meanings possessed by each part of a scholarly article. For instance, it is possible that some semantic annotations of a higher layer can cause the specification of new meanings to a lower layer.</p> 
         <p>This causal relationship is called <em>downward causation</em> <span rel="frbr:part"><a id="campbell1974-p2" about="#campbell1974-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#campbell1974"> </a></span>, and it has been one of the main objections to a purely reductionist approach for the description of the composition and behaviour of a biological system. Downward causation can be defined as a converse of the principle of compositionality: higher layers of a biological system can cause changes to its lower layers. Thus, in the context of the aforementioned eight layers of scholarly articles, it would be possible, for instance, to infer new meanings for the elements annotated in layer 3 by applying the downward causation from layer 4 – e.g. by explicitly marking a section as bibliography of an article (layer 3) if all the child elements that such a section contains (except its title) have been referenced somewhere within the article (layer 4).</p>
         <figure id="fig-layers">
            <p>
               <img src="img-2017-09-25/layers.png"
                  alt="Two graphs depicting possible uses of the principle of compositionality and of downward causation in the context of scholarly articles. The graph on the left depicts a pure application of the sole principle of compositionality (described by the bottom-to-top black arrows in the figure), where the information in a particular layer is totally derived from the information available in the previous one. In the graph on the right, the information in each layer can be derived by means of the information made available by one or more of the lower layers (principle of compositionality) or by one or more of the higher layers (downward causation, described by the top-to-bottom blue arrows in the figure)."/>
            </p>
            <figcaption>Two graphs depicting possible uses of the principle of compositionality and of downward causation in the context of scholarly articles. The graph on the left depicts a pure application of the sole principle of compositionality (described by the bottom-to-top black arrows in the figure), where the information in a particular layer is totally derived from the information available in the previous one. In the graph on the right, the information in each layer can be derived by means of the information made available by one or more of the lower layers (principle of compositionality) or by one or more of the higher layers (downward causation, described by the top-to-bottom blue arrows in the figure).</figcaption>
         </figure>
         <p>The graph on the right in <a href="#fig-layers"></a> illustrates the simultaneous use of the principle of compositionality and that of downward causation for inferring the various meanings (at different layers) associated with the parts of a scholarly article. It admits the possibility that a layer can convey meaningful information to any of the higher <em>or</em> lower layers. Of course, in order to use the principles of compositionality and downward causation for inferring the characterization of the various parts of a scholarly article, it is important to clarify what are their main components – i.e. the <em>parts</em>  of an expression, their <em>meanings</em>, and the <em>functions</em> that enable either the compositionality or downward causation between layers. In the context of scholarly articles, I define these three aspects as follows:</p>
         <ul>
            <li><p>a <em>part</em> of a scholarly article is any content enclosed by a particular marker – for instance, if we consider a scholarly article stored with an XML-like markup language, each markup element defines a particular part of that scholarly article. In the example shown in <a href="#fig-markup"></a>, the empty boxes with red border, the blue-underlined strings, and the italic and strong strings are delimiting various parts of the scholarly article, represented by specific markup elements in the related XML sources;</p></li>
            <li><p>the <em>meaning</em> of each part is an informative specification of the type or property characterizing that part. In the example shown in <a href="#fig-markup"></a>, the red labels with white text, as well as the pink rectangles, define specific semantics of some of the article parts;</p></li>
            <li><p>a <em>function</em> is an associative rule that allows, given particular known premises, the specification of a meaning to a particular part of a scholarly article.</p></li>
         </ul>
         <figure id="fig-markup">
            <p>
               <img src="img-2017-09-25/markup.png"
                  alt="The partial HTML version of a portion of the article entitled &quot;The CrebA/Creb3-like transcription factors are major and direct regulators of secretory capacity&quot; [top panel (A)], and the same containment structure [bottom panel (B)] stored according to a fictional XML-based language, where no meaningful textual or visual content is explicit. The empty boxes with a red border, the blue-underlined strings, as well as the italic and strong strings, describe the various parts of the article. The pink rectangles delimit in-text reference pointers to some bibliographic references, while the meaning of the other parts is defined by means of the red labels with white text."/>
            </p>
            <figcaption>The partial HTML version of a portion of the article entitled <q>The CrebA/Creb3-like transcription factors are major and direct regulators of secretory capacity</q> <span rel="frbr:part"><a id="fox2010-p1" about="#fox2010-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#fox2010"> </a></span> [top panel (A)], and the same containment structure [bottom panel (B)] stored according to a fictional XML-based language, where no meaningful textual or visual content is explicit. The empty boxes with a red border, the blue-underlined strings, as well as the italic and strong strings, describe the various parts of the article. The pink rectangles delimit in-text reference pointers to some bibliographic references, while the meaning of the other parts is defined by means of the red labels with white text.</figcaption>
         </figure>
         <p>Using the aforementioned definitions, we can iteratively apply rules following the principles of compositionality and downward causation so as to associate various meanings to article parts. Starting from the pure syntactical containment of certain parts, we can derive their structural semantics, their rhetoric, and other semantic representations of the article. For instance, recalling the stratification into eight layers introduced above, it is possible to create rules that, starting from a low-level definition of the structure of an article (e.g. the organisation of the markup elements that have been used to describe its content – layer 1), permit each markup element to be defined according to more general compositional patterns depicting its structure (e.g. the fact that a markup element can behave like a block or an inline item – layer 2). Again, starting from the definitions in the first two layers, one can go on to characterize the semantics of each markup element according to specific categories defining its structural behaviour (e.g. paragraph, section, list, figure, etc. – layer 3). Along the same lines, one can further derive the rhetorical organisation of a scholarly article, identifying the argumentative role of each part: Introduction, Methods, Material, Experiment, inline reference, etc. (layer 4). In addition, as mentioned above, one can use some of the characterizations specified in layer 4 to specify more precisely the parts annotated in layer 3 (e.g. to identify the bibliography).</p>
         <p>All these associations should be specifiable without considering either the natural language in which the paper is written or the particular markup language in which it is stored. For instance, the two examples depicted in <a href="#fig-markup"></a> show that a mechanism developed to infer the semantics of the various parts of the first article (A) should be able to assign the same semantics to parts of the second article (B), since they share the same syntactic containment between article parts.</p>
      </section>
      <section id="cise" about="#cise" typeof="deo:Contribution doco:Section">
         <h1 property="dcterms:title">Compositional and iterative semantic enhancement of scholarly articles</h1>
         <p>Taking inspiration from the ideas introduced in <a href="#pathway"> </a>, and restricting the possible input documents to the scholarly articles available in a reasonable markup language (e.g. an XML-like language), one can propose an approach for retrieving the higher-level characterizations of the parts of a scholarly article starting from their lower-level conceptualisations (by means of the principle of compositionality) and vice versa (by means of the downward causation). I have named this approach <em>compositional and iterative semantic enhancement</em> (or <em>CISE</em>, pronounced <em>size</em>) of scholarly articles. The following conditions should be satisfied when applying CISE:</p>
         <ul>
            <li>
               <p>[<strong>hierarchical markup</strong>] the source of a scholarly article should be available in (or easily converted into) a markup language that can convey the hierarchical containment of the various parts of scholarly articles;</p>
            </li>
            <li>
               <p>[<strong>language agnosticism</strong>] there is no need to have a prior knowledge of the natural language used for writing the scholarly article;</p>
            </li>
            <li>
               <p>[<strong>layer inter-dependency</strong>] a layer describing a particular conceptualisation of the parts of a scholarly article should depend on the conceptualisation of at least one other lower or higher layer;</p>
            </li>
            <li>
               <p>[<strong>inter-domain reuse</strong>] some of the typical structural and semantic aspects of scholarly articles should be shared across different research domains (e.g. abstract, introduction, conclusions);</p>
            </li>
            <li>
               <p>[<strong>intra-domain reuse</strong>] scholarly documents within a specific domain should share several structural and semantic aspects, even if these are not adopted by other research domains (e.g. the <q>related works</q> section is used in Computer Science articles, while it is not used in Life Science articles).</p>
            </li>
         </ul>
         <figure id="fig-algorithm">
            <pre><code>
1   def cise(document_set, annotation_set, rule_list):
2       initial_annotations, final_annotations = -1, 0
3       
4       while initial_annotations &lt; final_annotations:
5           initial_annotations = len(annotation_set)
6           final_annotations = initial_annotations
7              
8           for rule in rule_list:
9               annotations_to_add, annotations_to_remove = apply(rule, (document_set, annotation_set))
10              annotation_set -= annotations_to_remove
11              annotation_set |= annotations_to_add          
12          
13              final_annotations += len(annotations_to_add | annotations_to_remove)
14      
15      return annotation_set
            </code></pre>
            <figcaption>A Python-like pseudo-code describing CISE.</figcaption>
         </figure>
         <p>The pseudo-code shown in <a href="#fig-algorithm"></a> introduces the main procedure of CISE. It works by taking three objects as inputs (line 1): a set of marked-up documents to process, a set of annotations referring to the various parts contained in the documents, and a list of rules responsible for inferring new annotations from the existing annotations associated to the documents. Each rule is actually a function taking two parameters as input: a set of documents and a set of annotations. A rule can be run or not run according to the current status of the inputs it receives. For instance, some existing annotations activate the application of a particular rule on a certain document, while others do not. In principle, a rule can simultaneously process more than one document in the input document set, and it could thus find common patterns across documents. The output of a rule is a tuple <code>to_add, to_remove</code>, that are two sets of annotations to be added to and removed from the current set of annotations.</p>
         <p>Each annotation is a tuple <code>document<sub>i</sub>, layer<sub>j</sub>, property<sub>k</sub></code> where:</p>
         <ul>
            <li><p><code>document<sub>i</sub></code> is the document where the annotation has been specified;</p></li>
            <li><p><code>layer<sub>j</sub></code> is the layer defining the kind of information depicted by the annotation;</p></li>
            <li><p><code>property<sub>k</sub></code> is a set of statements related to a particular part (i.e. a markup element) of <code>document<sub>i</sub></code>.</p></li>
         </ul>
         <p>After the initialization of some variables (line 2), the main loop of CISE (line 4) continues until no annotations are added or removed from the current set of available annotations. The rationale behind this choice is that the application of the rules can change the status of the specified set of annotations and, consequently, it can create the premises for running a rule that was not previously activated. The following lines (5-6) set the variables that are used for checking if some modifications to the set of annotations are introduced as consequence of an iteration.</p>
         <p>The next loop (lines 8-11) is responsible for applying all the rules to all the documents using all the annotations specified as input. As anticipated, the application of a rule returns two sets (line 9): one containing the annotations that should be added, and the other containing the annotations that should be removed. These are then removed from (line 10, where <code>-</code> is the intersection operator between sets) and added to (line 11, where <code>|</code> is the union operator between sets) the current set of annotations. Finally, the variable <code>final_annotations</code> is incremented with the number of annotations added to/removed from the current set of annotations (line 13).</p>
         <p>When application of all the rules results in no further modifications to the current set of annotations, the algorithm terminates and returns the updated annotation set (line 15). Otherwise, the algorithm runs a new iteration of the main loop (starting from line 5).</p>
         <p>In the following section, I describe the outcomes of some implementations of CISE that I have developed with colleagues in my research group. These outcomes provide the first evidence of the feasibility of CISE for inferring the characterizations of parts of a scholarly article characterized in different layers, each depicting a particular kind of information. These outcomes provide a partial positive answer to the research question introduced in <a href="#introduction"></a> – namely whether it is possible to derive the semantic and rhetorical representation of a scholarly article from its syntactic organisation.</p>
      </section>
      <section id="evidence" about="#evidence" typeof="deo:Evaluation doco:Section">
         <h1 property="dcterms:title">Implementations of CISE</h1>
         <p>In recent years, I have experimented extensively, with other colleagues in my research group, with possible paths for the implementation of CISE. Our goal, starting from the pure syntactic containment of the various parts comprising scholarly articles, was to derive additional semantic descriptions of them. Each implementation of CISE we developed aimed at inferring new annotations related to one layer only, describing a specific kind of information.</p>
         <p>In our experiments, all the annotations of a layer are defined according to a particular ontology. To this end, we have developed a collection of ontologies that can be used to describe the first four layers introduced in <a href="#pathway"></a>, namely:</p>
         <ol>
            <li>
               <p>syntactic containment: <a rel="cito:linksTo" href="http://www.essepuntato.it/2008/12/earmark">EARMARK</a> 
                  <span rel="frbr:part"><a id="diiorio2011-p1" about="#diiorio2011-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2011"> </a></span> provides an ontologically precise definition of markup that instantiates the markup of a text document as an independent OWL document outside of the text strings it annotates;</p>
            </li>
            <li>
               <p>syntactic structures: the <a rel="cito:linksTo" href="http://www.essepuntato.it/2008/12/pattern">Pattern Ontology</a> 
                  <span rel="frbr:part"><a id="diiorio2014-p1" about="#diiorio2014-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2014"> </a></span> permits the segmentation of the structure of digital documents into a small number of atomic components, a set of the structural patterns that can be manipulated independently and re-used in different contexts;</p>
            </li>
            <li>
               <p>structural semantics: <a rel="cito:linksTo" href="http://purl.org/spar/doco">DoCO, the Document Components Ontology</a> 
                  <span rel="frbr:part"><a id="constantin2016-p1" about="#constantin2016-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#constantin2016"> </a></span> provides a vocabulary for the structural document components (paragraph, section, list, figure, table, etc.); and</p>
            </li>
            <li>
               <p>rhetorical components: <a rel="cito:linksTo" href="http://purl.org/spar/deo">DEO, the Discourse Elements Ontology</a> 
                  <span rel="frbr:part"><a id="constantin2016-p2" about="#constantin2016-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#constantin2016"> </a></span>) provides a structured vocabulary for rhetorical elements within documents (introduction, discussion, acknowledgements, etc.).</p>
            </li>
         </ol>
         <p>The identification of all the information related to the aforementioned layers is a quite complex work of analysis and derivation. These implementations are a clear evidence that the principles and the approach depicted by CISE are sound, at least to a certain extent, and that the automatic enhancement of scholarly articles by means of Semantic Publishing technologies can be achieved without necessarily using tools that rely on natural language processing or specific markup schemas. In the following subsections, we briefly introduce the outcomes of our experimentations with CISE<a href="#implementations"></a>.</p>
         <section id="layer1-layer2" rel="frbr:part" resource="#layer1-layer2">
            <h1 property="dcterms:title" typeof="doco:Section">From containment to structural patterns</h1>
            <p>Understanding how scholarly documents can be segmented into structural components, which can then be manipulated independently for different purposes, is a topic that my colleagues and I have studied extensively in the past. The main outcome of this research <span rel="frbr:part"><a id="diiorio2014-p2" about="#diiorio2014-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2014"> </a></span> is the proposal of a theory of structural patterns for digital documents that is sufficient to express what most users need in terms of document constituents and components when writing scholarly papers.</p>
            <p>The basic idea behind this theory – which has been derived by analysing best practice in existing XML grammars and documents <span rel="frbr:part"><a id="vitali2005-p1" about="#vitali2005-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#vitali2005"> </a></span> – is that each element of a markup language should comply with one and only one structural pattern, depending on the fact that the element:</p>
            <ul>
               <li>
                  <p>can or cannot contain text (+t in the first case, -t otherwise);</p>
               </li>
               <li>
                  <p>can or cannot contain other elements (+s in the first case, -s otherwise);</p>
               </li>
               <li>
                  <p>is contained by another element that can or cannot contain text (+T in the first case, -T otherwise).</p>
               </li>
            </ul>
            <p>By combining all these possible values –  ±t, ±s, and ±T – we obtain eight core structural patterns: inline, block, popup, container, atom, field, milestone, and meta. These patterns are described in the <a rel="cito:linksTo" href="http://www.essepuntato.it/2008/12/pattern">Pattern Ontology</a> and are summarised in <a href="#fig-pattern"></a>.</p>
            <figure id="fig-pattern">
               <p><img src="img-2017-09-25/pattern.png" alt="The taxonomical relations between the classes defined in the Pattern Ontology. The arrows indicate sub-class relationships between patterns (e.g. Mixed is sub-class of Structured), while the values ±t, ±s, and ±T between square brackets indicate the compliance of each class to the theory of patterns. In particular, the top yellow classes define generic properties that markup elements may have, while the bottom light-blue classes define the eight patterns identified by our theory. Note that no Block- and Inline-based elements can be used as root elements of a pattern-based document."/></p>
               <figcaption>The taxonomical relations between the classes defined in the Pattern Ontology. The arrows indicate sub-class relationships between patterns (e.g. Mixed is sub-class of Structured), while the values ±t, ±s, and ±T between square brackets indicate the compliance of each class to the theory of patterns introduced in <span rel="frbr:part"><a id="diiorio2014-p3" about="#diiorio2014-p3" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2014"> </a></span>. In particular, the top yellow classes define generic properties that markup elements may have, while the bottom light-blue classes define the eight patterns identified by our theory. Note that no Block- and Inline-based elements can be used as root elements of a pattern-based document.</figcaption>
            </figure>
            <p>In <span rel="frbr:part"><a id="diiorio2014-p4" about="#diiorio2014-p4" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2014"> </a></span>, colleagues and I have experimented with a CISE implementation for assigning structural patterns to markup elements in XML sources, without relying on any background information about the vocabulary, its intended meaning, its schema, and the natural language in which they have been written. The main steps of the algorithm implemented are shown in <a href="#fig-algorithm-layer1-layer2"></a>.</p>
            <figure id="fig-algorithm-layer1-layer2">
               <pre><code>
1   def implementation1(xml_documents)
2       layer1 = cise(xml_documents, set(), [ convert_into_earmark ])
3   
4       patterns = cise(xml_documents, layer1, [ 
5           assign_t_s_properties,
6           assign_T_properties,
7           assign_patterns])
8   
9       layer2 = cise(xml_documents, patterns, [
10          reach_local_coherence,
11          reach_global_coherence])
12      
13      return layer2
               </code></pre>
               <figcaption>A Python-like pseudo code reusing the code introduced in <a href="#fig-algorithm"></a> for creating the annotations related to the first two layers introduced in <a href="#evidence"></a>.</figcaption>
            </figure>   
            <p>This new algorithm is organised in three main steps, each re-using the mechanism introduced in <a href="#fig-algorithm"></a>. The first step (line 2) retrieves all the annotations referring to the first layer (i.e. syntactic containment) by representing the XML input documents in input using EARMARK <span rel="frbr:part"><a id="diiorio2011-p2" about="#diiorio2011-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2011"> </a></span>. This transformation is handled by the function <code>convert_into_earmark</code> which populates the initially empty set of annotations with statements that guarantee a complete ontological description of the document markup.</p>
            <p>The second step (lines 4-7) assigns, to each instance of each element of each document, the ±t and ±s values according to the kinds of nodes (i.e. textual nodes and/or markup elements) such instance contains (function <code>assign_t_s_properties</code>), and the ±T values according to the previous assignments (function <code>assign_T_properties</code>). Finally, the full structural pattern is specified using all the aforementioned assignments (function <code>assign_patterns</code>).</p>
            <p>The third step (lines 9-11) is responsible for harmonising the pattern association of all the instances of the same element. For instance, it would be possible that, in the same document, two instances of an element <q>x</q> are assigned to two different patterns, e.g. <em>atom</em> and <em>inline</em>. However, occasionally, it would be possible to generalise these assignments so as to have the same pattern specified for all the instances of the same element – e.g. in the previous example, all the instances of <q>x</q> assigned to the pattern <em>atom</em> can be safely assigned to the pattern <em>inline</em> since it is more flexible, allowing the containment of both text nodes and markup elements. This operation of harmonisation, applied to all the pattern assignments of a document, aims at reaching the <em>local coherence</em> of the assignments (function <code>reach_local_coherence</code>) – i.e. the situation in which all the instances of each markup element in a document are assigned to the same pattern. It is worth mentioning that there are situations where such local coherence cannot be reached for some documents. In these cases, all their pattern assignments are removed, so as not to be processed by the following rules. In addition, this harmonisation operation can be applied to all the instances of all the markup elements contained in all the documents that have been found locally coherent. In this case, we talk about reaching the <em>global coherence</em> of the pattern assignments across the corpus of documents (function <code>reach_global_coherence</code>). Finally, the results of these associations are returned (line 13).</p>
            <figure id="fig-pattern-assignments">
               <p><img src="img-2017-09-25/pattern-example.png" alt="Four snapshots of the same excerpt of an XML document, describing the execution of the algorithm."/></p>
               <figcaption>Four snapshots of the same excerpt of an XML document, describing the execution of the algorithm introduced in <a href="#fig-pattern-assignments"></a>.</figcaption>
            </figure>
            <p>In <a href="#fig-pattern-assignments"></a>, I show an execution of the algorithm in <a href="#fig-algorithm-layer1-layer2"></a> using the document introduced in the panel B of <a href="#fig-markup"></a>. In particular, panel A of <a href="#fig-pattern-assignments"></a> shows the outcomes of the function <code>assign_t_s_properties</code>, supposing that the containment relations of the elements have been already described by the annotations included in layer 1. Panel B completes the previous assignments with those introduced by the function <code>assign_T_properties</code>. Panel C depicts only the outcomes of the function <code>assign_patterns</code> (without showing again the previous assignments). Finally, panel D shows some modifications of the pattern assignments to reach local and global coherence (functions <code>reach_local_coherence</code> and <code>reach_global_coherence</code>).</p>
            <p>In order to understand what extent structural patterns are used in different communities, we have executed this CISE-based algorithm on a large set of documents stored using different XML-based markup languages. Some of these markup languages, e.g. TEI <span rel="frbr:part"><a id="teiconsortium2016-p1" about="#teiconsortium2016-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#teiconsortium2016"> </a></span> and DocBook <span rel="frbr:part"><a id="walsh2010-p1" about="#walsh2010-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#walsh2010"> </a></span>, are not inherently pattern-based – i.e. it is possible in principle to use them to write locally/globally incoherent documents. For instance, a DocBook document that is not pattern-based in introduced in <a href="#fig-no-pattern"></a>.</p>
            <figure id="fig-no-pattern">
               <pre><code>
&lt;book xmlns="http://docbook.org/ns/docbook" version="5.0">
  &lt;title>Title of the book&lt;/title>
  &lt;chapter>
    &lt;title>Title of the chapter&lt;/title>
    &lt;para>Simple paragraph&lt;/para>
    &lt;para>
      A paragraph containing a list
      &lt;itemizedlist>
        &lt;listitem>
          &lt;para>List item&lt;/para>
        &lt;/listitem>
      &lt;/itemizedlist>
    &lt;/para>
    &lt;itemizedlist>
      &lt;listitem>
        &lt;para>Item of a list outside a paragraph&lt;/para>
      &lt;/listitem>
    &lt;/itemizedlist>
  &lt;/chapter>
&lt;/book>
</code></pre>
               <figcaption>An example of a DocBook document that is not pattern-based. The only possible configuration is to associate the Inline pattern with all the elements except <code>book</code>, that must be associated with the pattern Block. However, as explained in <a href="#fig-pattern"></a>, a Block-based element cannot be the root element of a pattern-based XML document.</figcaption>
            </figure>
            <p>This experimentation allowed us to reached the following conclusions:</p>
            <ul>
               <li about="#main-argument-evidence1" typeof="amo:Evidence" rel="amo:proves" resource="#main-argument-claim">
                  <p><span about="#main-argument-evidence1" property="dcterms:description" rel="amo:supports" resource="#main-argument-warrant">in a community (e.g., a conference proceedings or a journal) that uses a permissive non-pattern-based markup language, most authors nevertheless use a pattern-based subset of such language for writing their scholarly articles</span>. This conclusion has been derived by analysing the outcomes of the algorithm execution, as illustrated in <span rel="frbr:part"><a id="diiorio2014-p5" about="#diiorio2014-p5" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2014"> </a></span>;</p>
               </li>
               <li about="#main-argument-evidence2" typeof="amo:Evidence" rel="amo:proves" resource="#main-argument-claim">
                  <p><span about="#main-argument-evidence2" property="dcterms:description" rel="amo:supports" resource="#main-argument-warrant">only a small number of pattern-based documents coming from different communities of authors, all stored using the same markup language, is needed for automatically generating generic visualisations for all documents stored in that markup language (regardless of whether they are pattern-based or not) included in the communities in consideration</span>. This conclusion has been empirically demonstrated by developing a prototypical tool, called PViewer, which implements such automatic visualisation mechanism, as introduced in <span rel="frbr:part"><a id="diiorio2014-p6" about="#diiorio2014-p6" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2014"> </a></span>.</p>
               </li>
            </ul>
            <p>Once the algorithm has identified that all the individuals of the markup element <q>x</q> included in pattern-based documents of a certain community comply with a particular pattern, it is then possible implicitly to associate the same pattern to all the individual of the same element included in non-pattern-based documents of the same community. As a consequence, these assignments can be used to provide a guide to authors (or even to automatic tools) for adjusting the current organisation of non-pattern-based documents so as to convert them into proper pattern-based ones.</p>
         </section>
         <section id="layer2-layer3" rel="frbr:part" resource="#layer2-layer3">
            <h1 property="dcterms:title" typeof="doco:Section">From structural patterns to structural semantics</h1>
            <p>The systematic use of the patterns introduced in <a href="#layer1-layer2"> </a> allows authors to create unambiguous, manageable and well-structured documents. In addition, thanks to the regularity they provide, it is possible to perform complex operations on pattern-based documents (e.g. visualisation) even without knowing their vocabulary. Thus, it should be possible to implement reliable and efficient tools and algorithms that can make hypotheses regarding the meanings of document fragments, that can identify singularities, and that can study global properties of sets of documents.</p>
            <p>Starting from these premises, my colleagues and I have implemented another algorithm to infer layer 3 annotations from the structural patterns retrieved using with the algorithm introduced in <a href="#fig-algorithm-layer1-layer2"></a> <span rel="frbr:part"><a id="diiorio2013-p1" about="#diiorio2013-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2013"> </a></span>. Specifically, we use the entities defined in the <a rel="cito:linksTo" href="http://purl.org/spar/doco">Document Components Ontology (DoCO)</a> (excluding, on purpose, those defined in other imported ontologies) to mark up elements of documents that have specific structural connotations, such as paragraphs, sections, titles, lists, figures, tables, etc.</p>
            <figure id="fig-algorithm-layer2-layer3">
               <pre><code>
1   def implementation2(xml_documents):
2       layer2 = implementation1(xml_documents)
3       
4       layer3 = cise(xml_documents, layer2, [ 
5           identify_paragraphs,
6           identify_sections,
7           identify_section_titles,
8           identify_body_matter,
9           ...])
10      
11      return layer3
               </code></pre>
               <figcaption>A Python-like pseudo code reusing the code introduced in <a href="#fig-algorithm"></a> and <a href="#fig-algorithm-layer1-layer2"></a>, for adding the annotations related to the third layer.</figcaption>
            </figure>
            <p>A pseudo code of this new algorithm is introduced in <a href="#fig-algorithm-layer2-layer3"></a>. It is organised in two steps. First, starting from the input XML documents, it retrieves all the annotations of the first two layers by reusing the algorithm discussed in <a href="#layer1-layer2"></a> (line 2). Then, the following step (lines 4-9) reuses the CISE algorithm introduced in <a href="#cise"></a>, by specifying the annotation retrieved previously and the list of functions, where each is responsible for identifying all the markup elements that act according to a specific structural behaviour (e.g. paragraph) in the documents. Each of these rules implements some heuristics that have been derived by analysing how the structural patterns are used in scholarly documents, as detailed in <span rel="frbr:part"><a id="diiorio2013-p2" about="#diiorio2013-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2013"> </a></span> with more detail. For instance, <code>identify_paragraphs</code> associate the type <code>doco:Paragraph</code> to all the instances of the same markup element <q>x</q> that is the block element (in terms of structural patterns) with most occurrences (i.e. instances) in the document. If we consider the example in the panel D of <a href="#fig-pattern-assignments"></a>, all the instances of the element <q>c</q> will be annotated as paragraphs.</p>
            <p>We have run the algorithm introduced in <a href="#fig-algorithm-layer2-layer3"></a> on the XML sources of all the articles published in the Proceedings of Balisage (<a rel="cito:linksTo" href="http://balisage.net/">http://balisage.net</a>), which are marked up in DocBook <span rel="frbr:part"><a id="walsh2010-p2" about="#walsh2010-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#walsh2010"> </a></span>. We obtained quite high overall values of precision and recall (i.e. 0.887 and 0.890 respectively) when comparing the results of the algorithm with a gold standard we created manually by assigning structural characterizations to all the markup elements defined in DocBook. By analysing the outcomes of the algorithm execution, as illustrated in <span rel="frbr:part"><a id="diiorio2013-p3" about="#diiorio2013-p3" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2013"> </a></span>, we have reached the following conclusion:</p>
            <ul>
               <li about="#main-argument-evidence3" typeof="amo:Evidence" rel="amo:proves" resource="#main-argument-claim">
                  <p about="#main-argument-evidence3" property="dcterms:description" rel="amo:supports" resource="#main-argument-warrant">only a small number of pattern-based documents, written by different authors of the same community, is needed for extracting the structural semantics of the main components of all the documents produced by that community.</p>
               </li>
            </ul>
         </section>
         <section id="layer3-layer4" rel="frbr:part" resource="#layer3-layer4">
            <h1 property="dcterms:title" typeof="doco:Section">From structural semantics to rhetorical components and back</h1>
            <p>The work presented in <span rel="frbr:part"><a id="diiorio2013-p4" about="#diiorio2013-p4" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2013"> </a></span> was further extended by applying two additional algorithms that have allowed us to retrieve specific rhetorical components in the document, i.e. the <em>references</em>. We then used this rhetorical characterization to assign more precise definitions to the structural entities retrieved by the algorithm introduced in <a href="#fig-algorithm-layer2-layer3"></a>.</p>
            <p>According to the <a href="">Discourse Element Ontology (DEO)</a>, the ontology used to represent the annotations of layer 4, a <em>reference</em> is an element that references to a specific part of the document or to another publication. Thus, this category describes any bibliographic reference, any in-text reference pointer to a bibliographic reference, and any pointer to other article items such as figures or tables. These references are recognised by means of the algorithm introduced in <a href="#fig-algorithm-layer3-layer4"></a>.</p>
            <figure id="fig-algorithm-layer3-layer4">
               <pre><code>
1   def implementation3(xml_documents):
2       layer3 = implementation2(xml_documents)
3       
4       layer4 = cise(xml_documents, layer3, [ identify_references ])
5       
6       return layer4                 
               </code></pre>
               <figcaption>A Python-like pseudo code reusing the code introduced in <a href="#fig-algorithm"></a> and <a href="#fig-algorithm-layer2-layer3"></a> for adding the annotations related to the fourth layer.</figcaption>
            </figure>
            <p>This new algorithm is organised in two steps. First, starting from the input XML documents, it retrieves all the annotations of the first three layers by reusing the algorithm discussed in <a href="#layer2-layer3"></a> (line 2). Then, the following step (line 4) reuses the CISE algorithm introduced in <a href="#cise"></a>, by specifying the annotations retrieved previously and a particular function, <code>identify_references</code>, that is responsible for annotating all the markup elements that act as references. In particular, this function associates the type <code>deo:Reference</code> to all the instances of elements that are compliant either with the pattern <em>atom</em> or the pattern <em>milestone</em>, and that have an attribute <q>x</q> with value <q>#</q> + <q>v</q>, where <q>v</q> is the value of another attribute <q>y</q> of another element.</p>
            <p>Although this rhetorical characterization of article parts only identifies references, these new annotations allow us to infer new meanings for the elements annotated in layer 3, by applying downward causation from layer 4. Specifically, this information about the references allowed us to identify the Bibliography section of an article, by identifying the element of type <code>doco:Section</code> (layer 3) whose children elements, except the section title, are all referenced in the main text.</p>
            <figure id="fig-algorithm-layer4-layer3">
               <pre><code>
1   def implementation4(xml_documents):
2       layer4 = implementation3(xml_documents)
3       
4       layer3 = cise(xml_documents, layer4, [ 
5           identify_bibliographic_reference_lists,
6           identify_bibliographies])
7       
8       return layer3                 
               </code></pre>
               <figcaption>A Python-like pseudo code reusing the code introduced in <a href="#fig-algorithm"></a> and <a href="#fig-algorithm-layer3-layer4"></a>, that adds annotations related to the third layer using downward causation.</figcaption>
            </figure>
            <p>The algorithm in <a href="#fig-algorithm-layer4-layer3"></a> implements this: after retrieving all fourth layer annotations (line 2), it reuses the CISE algorithm introduced in <a href="#cise"></a> so as to annotate all the lists that are bibliographic reference lists (function <code>identify_bibliographic_reference_lists</code>) and all the sections that are Bibliography sections (function <code>identify_bibliographies</code>).</p>
         </section>
      </section>
      <section id="limitations" about="#limitations" typeof="deo:Discussion doco:Section">
         <h1 property="dcterms:title">Limitations and future directions</h1>
         <p>In <a href="#evidence"></a> I have shown how the approach proposed in <a href="#cise"></a> can be implemented to return annotations belonging the first four layers introduced in <a href="#pathway"></a>. It also presents some issues that cannot be addressed by looking only at the syntactical containment of article parts. The most important issue is this: since CISE focusses on article parts that must be clearly marked-up in some way, all the other portions of the article text are simply discarded. By design CISE does not undertake the analysis of natural language text. There are several existing applications, such as Named Entity Recognition tools (NER) <span rel="frbr:part"><a id="gangemi2013-p1" about="#gangemi2013-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#gangemi2013"> </a></span> and other NLP technologies (e.g. <span rel="frbr:part"><a id="sateli2015-p2" about="#sateli2015-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#sateli2015"> </a></span>), that can be used for this purpose.</p>
         <p>CISE is intrinsically limited by some of the conditions, introduced in <a href="#cise"></a>, necessary for its implementation. The most limiting is the requirement that the article to be analysed should be appropriately marked up by means of some (e.g. XML-based) markup language. While it is not necessary to know the particular grammar and vocabulary of the markup language used, it is crucial that the article parts are organised hierarchically according to appropriate containment principles. For instance, in an HTML-based article, all the section-subsection relations should be explicitly defined by means of nested <code>section</code> elements. The common usage of headings of different levels (i.e. <code>h1</code>-<code>h6</code> elements) within a flat structure (e.g. an <code>article</code> element) is inadequate for this, since it does not explicitly define the intended hierarchical organisation of the sections<a href="#flat-structure"></a>.</p>
         <p>CISE depends on the theoretical backgrounds introduced in <a href="#pathway"></a>, namely the principles of compositionality and downward causation. The other conditions introduced in <a href="#cise"></a> are less strict and need a more careful investigation. In particular, while scholarly documents can be written in different natural languages, their main constituents common across the whole scholarly communication domain. Of course, the presentation of research articles can vary according to the particular domain – e.g. Life Sciences articles usually follow a well-defined structure, while Computer Science articles are usually organised in a less conservative way. However, they all follow generic underlying ways of organising the arguments supporting the research conclusions – even if some aspects are more commonly found in one domain rather than another (e.g. Life Science articles typically have a Background section, while Computer Science articles have a Related Works section, whose function, while similar, is different in important aspects). Nevertheless, my hypothesis (partially supported by existing studies, e.g. <span rel="frbr:part"><a id="maswana2015-p1" about="#maswana2015-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#maswana2015"> </a></span>) is that many of the ways of organising research articles are shared across the various research areas.</p>
         <p>Future extensions and new implementations of CISE will permit me to study such intra- and inter-domain patterns and similarities, identifying which particular structures and semantic connotations are shared between different research areas, and determining how much argumentative information is hidden behind quite simple syntactic structures. From such analysis, it might be possible to identify particular patterns of organisation of document parts that characterize certain domains or particular the types of papers (research papers, reviews, letters, etc.).</p>
         <p>It might also be possible to extend CISE to the remaining higher layers introduced in <a href="#pathway"></a>, each defined by a specific ontology: annotations about citation functions (target ontology: <a rel="cito:linksTo" href="http://purl.org/spar/cito">CiTO</a> <span rel="frbr:part"><a id="peroni2012-p1" about="#peroni2012-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#peroni2012"> </a></span>), argumentative organisation (target ontology: <a rel="cito:linksTo" href="http://www.essepuntato.it/2011/02/argumentmodel">AMO</a>), article categorization (target ontology: <a rel="cito:linksTo" href="http://purl.org/spar/fabio">FaBiO</a> <span rel="frbr:part"><a id="peroni2012-p2" about="#peroni2012-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#peroni2012"> </a></span>), and discipline clustering (target ontology: <a rel="cito:linksTo" href="http://dbpedia.org/ontology/">DBpedia Ontology</a> <span rel="frbr:part"><a id="lehmann2015-p1" about="#lehmann2015-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#lehmann2015"> </a></span>).</p>
      </section>
      <section id="conclusions" about="#conclusions" typeof="deo:Conclusion doco:Section">
         <h1 property="dcterms:title">Conclusions</h1>
         <p>In this article, I have introduced the <em>compositional and iterative semantic enhancement</em> (CISE) approach for the automated enrichment of scholarly articles with meaningful semantic annotations by means of Semantic Publishing technologies. Taking inspiration from past approaches that rely on the principles of compositionality and downward causation, the CISE strategy enables the automatic enhancement of the various parts comprising a scholarly article by means of an iterative process, providing additional semantic descriptions by combining the enhancements obtained in previous executions of the approach.</p>
         <p>I have also discussed the outcomes of past CISE experimentations that my colleagues and I have developed for the automatic annotation of document components in scholarly articles according to particular structural patterns (inline, block, etc.), structural semantics (paragraph, section, figure, etc.), and rhetorical components (i.e. references), as introduced in <a href="#evidence"> </a>. While these do not address all the layers of annotations sketched in <a href="#pathway"></a>, I think the outcomes described in <a href="#evidence"> </a> are acceptable pointers for claiming that some level of automatic semantic enhancement of scholarly articles is possible even in the presence of specific constraints such as the independence from the natural language used for writing such articles and the markup language used for storing their contents. Thus CISE provides at least a partial positive answer to the research question presented in <a href="#introduction"></a>: <q>Can the purely syntactic organisation of the various parts of a scholarly article convey something about its semantic and rhetorical representation, and to what extent?</q>. In the future, I plan to perform additional studies and experiments to further validate this claim.</p>
      </section>
      <section id="acknowledgements" about="#acknowledgements" typeof="doco:Section deo:Acknowledgements" role="doc-acknowledgements">
         <h1 property="dcterms:title">Acknowledgements</h1>
         <p>I would like to thank all the colleagues working at the <a href="http://dasplab.cs.unibo.it">Digital and Semantic Publishing Laboratory (DASPLab)</a> – namely Angelo Di Iorio, Francesco Poggi, and Fabio Vitali – who have shared with me their time and effort on these topics. I would also like to thank the Editors-in-Chief and the reviewers of the <a href="https://datasciencehub.net/">Data Science Journal</a> for their comments and suggestions – they have been fundamental for improving the quality and the narrative of this article. Last but not least, two big thanks to my Semantic Publishing mentor and fellow, David Shotton. Some years ago, he gave me a wonderful book, <q>The Music of Life: Biology beyond genes</q> written by Denis Noble, that has been the primary source of inspiration for CISE. In addition, David has carefully proofread of the whole text, improving drastically the readability of this article.</p>
      </section>
      <section id="references" about="#references" typeof="doco:Bibliography doco:Section" role="doc-bibliography" rel="frbr:part">
         <h1>References</h1>
         <ol id="reference-list" about="#reference-list" typeof="doco:BibliographicReferenceList" rel="frbr:part">
            <li id="bagnacani2014" role="doc-biblioentry" about="#bagnacani2014" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Andrea Bagnacani, Paolo Ciancarini, Angelo Di Iorio, Andrea Giovanni Nuzzolese, Silvio Peroni, Fabio Vitali (2014). The Semantic Lancet Project: A Linked Open Dataset for Scholarly Publishing. In EKAW (Satellite Events) 2014: 101-105. DOI: <a rel="biro:references" href="https://doi.org/10.1007/978-3-319-17966-7_10"><span rev="cito:cites" resource="">https://doi.org/10.1007/978-3-319-17966-7_10</span></a></p>
            </li>
            <li id="bernerslee2001" role="doc-biblioentry" about="#bernerslee2001" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Tim Berners-Lee, James Hendler, Ora Lassila (2001). The Semantic Web. Scientific American, 285 (5): 34-43. DOI: <a rel="biro:references" href="https://doi.org/10.1038/scientificamerican0501-34"><span rev="cito:cites" resource="">https://doi.org/10.1038/scientificamerican0501-34</span></a></p>
            </li>
            <li id="campbell1974" role="doc-biblioentry" about="#campbell1974" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Donald T. Campbell (1974). Downward causation in hierarchically organised biological systems. In Francisco Jose Ayala and Theodosius Dobzhansky (Eds.), Studies in the philosophy of biology: 179-186. DOI: <a rel="biro:references" href="https://doi.org/10.1007/978-1-349-01892-5_11"><span rev="cito:cites" resource="">https://doi.org/10.1007/978-1-349-01892-5_11</span></a></p>
            </li>
            <li id="comeau2013" role="doc-biblioentry" about="#comeau2013" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Donald C. Comeau, Rezarta Islamaj Doğan, Paolo Ciccarese, Kevin Bretonnel Cohen, Martin Krallinger, Florian Leitner, Zhiyong Lu, Yifan Peng, Fabio Rinaldi, Manabu Torii, Alfonso Valencia, Karin Verspoor, Thomas C. Wiegers, Cathy H. Wu, W. John Wilbur (2013). BioC: a minimalist approach to interoperability for biomedical text processing. Database, 2013: bat064. DOI: <a rel="biro:references" href="https://doi.org/10.1093/database/bat064"><span rev="cito:cites" resource="">https://doi.org/10.1093/database/bat064</span></a></p>
            </li>
            <li id="constantin2016" role="doc-biblioentry" about="#constantin2016" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Alexandru Constantin, Silvio Peroni, Steve Pettifer, David M. Shotton, Fabio Vitali (2016). The Document Components Ontology (DoCO). Semantic Web, 7 (2): 167-181. DOI: <a rel="biro:references" href="https://doi.org/10.3233/SW-150177"><span rev="cito:cites" resource="">https://doi.org/10.3233/SW-150177</span></a></p>
            </li>
            <li id="crick1966" role="doc-biblioentry" about="#crick1966" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Francis Crick (1966). Of Molecules and Men. University of Washington Press. ISBN: 1591021855. <a rel="biro:references" href="https://philpapers.org/rec/CRIOMA"><span rev="cito:cites" resource="">https://philpapers.org/rec/CRIOMA</span></a></p>
            </li>
            <li id="cyganiak2014" role="doc-biblioentry" about="#cyganiak2014" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Richard Cyganiak, David Wood, Markus Lanthaler (2014). RDF 1.1 Concepts and Abstract Syntax. W3C Recommendation 25 February 2014. <a rel="biro:references" href="https://www.w3.org/TR/rdf11-concepts/"><span rev="cito:cites" resource="">https://www.w3.org/TR/rdf11-concepts/</span></a></p>
            </li>
            <li id="diiorio2013_2" role="doc-biblioentry" about="#diiorio2013_2" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Angelo Di Iorio, Andrea G. Nuzzolese, Silvio Peroni (2013). characterizing citations in scholarly documents: the CiTalO framework. In ESWC 2013 Satellite Events - Revised Selected Papers: 66-77. DOI: <a rel="biro:references" href="http://doi.org/10.1007/978-3-642-41242-4_6"><span rev="cito:cites" resource="">http://doi.org/10.1007/978-3-642-41242-4_6</span></a></p>
            </li>
            <li id="diiorio2014" role="doc-biblioentry" about="#diiorio2014" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Angelo Di Iorio, Silvio Peroni, Francesco Poggi, Fabio Vitali (2014). Dealing with structural patterns of XML documents. Journal of the Association for Information Science and Technologies, 65 (9): 1884-1900. DOI: <a rel="biro:references" href="https://doi.org/10.1002/asi.23088"><span rev="dcterms:requires"><span about="#main-argument-backing-1" typeof="amo:Backing" rel="amo:backs" resource="#main-argument-warrant"><span about="" rel="cito:cites" resource="https://doi.org/10.1002/asi.23088">https://doi.org/10.1002/asi.23088</span></span></span></a></p>
            </li>
            <li id="diiorio2013" role="doc-biblioentry" about="#diiorio2013" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Angelo Di Iorio, Silvio Peroni, Francesco Poggi, Fabio Vitali, David Shotton (2013). Recognising document components in XML-based academic articles. In Proceedings of the 2013 ACM Symposium on Document Engineering (DocEng 2013): 181-184. DOI: <a rel="biro:references" href="https://doi.org/10.1145/2494266.2494319"><span rev="dcterms:requires"><span about="#main-argument-backing-2" typeof="amo:Backing" rel="amo:backs" resource="#main-argument-warrant"><span about="" rel="cito:cites" resource="https://doi.org/10.1145/2494266.2494319">https://doi.org/10.1145/2494266.2494319</span></span></span></a></p>
            </li>
            <li id="diiorio2011" role="doc-biblioentry" about="#diiorio2011" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Angelo Di Iorio, Silvio Peroni, Fabio Vitali (2011). A Semantic Web approach to everyday overlapping markup. Journal of the American Society for Information Science and Technologies, 62 (9): 1696-1716: DOI: <a rel="biro:references" href="https://doi.org/10.1002/asi.21591"><span rev="cito:cites" resource="">https://doi.org/10.1002/asi.21591</span></a></p>
            </li>
            <li id="diiorio2014_2" role="doc-biblioentry" about="#diiorio2014_2" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Angelo Di Iorio, Silvio Peroni, Fabio Vitali, Jacopo Zingoni (2014). Semantic Lenses to Bring Digital and Semantic Publishing Together. In Proceedings of the 4th Workshop on Linked Science 2014 (LISC2014): 12-23. <a rel="biro:references" href="http://ceur-ws.org/Vol-1282/lisc2014_submission_6.pdf"><span rev="cito:cites" resource="">http://ceur-ws.org/Vol-1282/lisc2014_submission_6.pdf</span></a></p>
            </li>
            <li id="fink2010" role="doc-biblioentry" about="#fink2010" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">J. Lynn Fink, Pablo Fernicola, Rahul Chandran, Savas Parastatidis, Alex Wade, Oscar Naim, Gregory B. Quinn, Philip E. Bourne (2010). Word add-in for ontology recognition: semantic enrichment of scientific literature. BMC Bioinformatics, 2010 (11): 103 DOI: <a rel="biro:references" href="https://doi.org/10.1186/1471-2105-11-103"><span rev="cito:cites" resource="">https://doi.org/10.1186/1471-2105-11-103</span></a></p>
            </li>
            <li id="fox2010" role="doc-biblioentry" about="#fox2010" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Rebecca M. Fox, Caitlin D. Hanlon, and Deborah J. Andrew (2010). The CrebA/Creb3-like transcription factors are major and direct regulators of secretory capacity. Journal of Cell Biology, 191 (3): 479-492. DOI: <a rel="biro:references" href="https://doi.org/10.1083/jcb.201004062"><span rev="cito:cites" resource="">https://doi.org/10.1083/jcb.201004062</span></a></p>
            </li>
            <li id="gangemi2013" role="doc-biblioentry" about="#gangemi2013" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Aldo Gangemi (2013). A Comparison of Knowledge Extraction Tools for the Semantic Web. In Proceedings of the 10th Extended Semantic Web Conference (ESWC 2013): 351-366. DOI: <a rel="biro:references" href="https://doi.org/10.1007/978-3-642-38288-8_24"><span rev="cito:cites" resource="">https://doi.org/10.1007/978-3-642-38288-8_24</span></a></p>
            </li>
            <li id="gangemi2017" role="doc-biblioentry" about="#gangemi2017" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Aldo Gangemi, Valentina Presutti, Diego Reforgiato Recupero, Andrea Giovanni Nuzzolese, Francesco Draicchio, Misael Mongiovì (2017). Semantic Web machine reading with FRED. Semantic Web, 8 (6). DOI: <a rel="biro:references" href="https://doi.org/10.3233/SW-160240"><span rev="cito:cites" resource="">https://doi.org/10.3233/SW-160240</span></a></p>
            </li>
            <li id="groth2010" role="doc-biblioentry" about="#groth2010" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Paul Groth, Andrew Gibson, Jan Velterop (2010). The anatomy of a nanopublication. Information Services and Use, 30 (1-2): 51-56. DOI: <a rel="biro:references" href="https://doi.org/10.3233/ISU-2010-0613"><span rev="cito:cites" resource="">https://doi.org/10.3233/ISU-2010-0613</span></a></p>
            </li>
            <li id="howard1980" role="doc-biblioentry" about="#howard1980" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">William A. Howard (1980). The formulae-as-types notion of construction. In Jonathan P. Seldin, J. Roger Hindley, To H.B. Curry: Essays on Combinatory Logic, Lambda Calculus and Formalism: 479-490. Boston, MA: Academic Press. ISBN: 978-0-12-349050-6. <a rel="biro:references" href="http://www.dcc.fc.up.pt/~acm/howard.pdf"><span rev="cito:cites" resource="">http://www.dcc.fc.up.pt/~acm/howard.pdf</span></a> (last visited May 30, 2017)</p>
            </li>
            <li id="jha2017" role="doc-biblioentry" about="#jha2017" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Rahul Jha, Amjad-Abu Jbara, Vahed Qazvinian, Dragomir R. Radev (2017). NLP-driven citation analysis for scientometrics. Natural Language Engineering, 23 (1): 93-130. DOI: <a rel="biro:references" href="https://doi.org/10.1017/S1351324915000443"><span rev="cito:cites" resource="">https://doi.org/10.1017/S1351324915000443</span></a></p>
            </li>
            <li id="odt2006" role="doc-biblioentry" about="#odt2006" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">JTC1/SC34 WG 6. (2006). ISO/IEC 26300:2006 - Information technology - Open Document Format for Office Applications (OpenDocument) v1.0. Geneva, Switzerland: International Organization for Standardization. <a rel="biro:references" href="http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=43485"><span rev="cito:cites" resource="">http://www.iso.org/iso/iso_catalogue/catalogue_tc/catalogue_detail.htm?csnumber=43485</span></a></p>
            </li>
            <li id="kim2000" role="doc-biblioentry" about="#kim2000" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Jongwoo Kim, Daniel X. Le, George R. Thoma (2000). Automated Labeling in Document Images. In Proceedings of Document Recognition and Retrieval VIII: 111-122. DOI: <a rel="biro:references" href="https://doi.org/10.1117/12.410828"><span rev="cito:cites" resource="">https://doi.org/10.1117/12.410828</span></a></p>
            </li>
            <li id="koh2007" role="doc-biblioentry" about="#koh2007" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Eunyee Koh, Daniel Caruso, Andruid Kerne, Ricardo Gutierrez-Osuna (2007). Elimination of junk document surrogate candidates through pattern recognition. In Proceedings of the 2007 ACM symposium on Document engineering (DocEng 2007): 187-195. DOI: <a rel="biro:references" href="https://doi.org/10.1145/1284420.1284466"><span rev="cito:cites" resource="">https://doi.org/10.1145/1284420.1284466</span></a></p>
            </li>
            <li id="lehmann2015" role="doc-biblioentry" about="#lehmann2015" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Jens Lehmann, Robert Isele, Max Jakob, Anja Jentzsch, Dimitris Kontokostas, Pablo N. Mendes, Sebastian Hellmann, Mohamed Morsey, Patrick van Kleef, Sören Auer, Christian Bizer (2015). DBpedia - A large-scale, multilingual knowledge base extracted from Wikipedia. Semantic Web, 6 (2): 167-195. DOI: <a rel="biro:references" href="https://doi.org/10.3233/SW-140134"><span rev="cito:cites" resource="">https://doi.org/10.3233/SW-140134</span></a></p>
            </li>
            <li id="liakata2010" role="doc-biblioentry" about="#liakata2010" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Maria Liakata, Simone Teufel, Advaith Siddharthan, Colin Batchelor (2010). In Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC 2010): 2054-2061. <a rel="biro:references" href="http://www.lrec-conf.org/proceedings/lrec2010/pdf/644_Paper.pdf"><span rev="cito:cites" resource="">http://www.lrec-conf.org/proceedings/lrec2010/pdf/644_Paper.pdf</span></a></p>
            </li>
            <li id="livingston2013" role="doc-biblioentry" about="#livingston2013" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Kevin M. Livingston, Michael Bada, Lawrence E. Hunter, Karin Verspoor (2013). Representing annotation compositionality and provenance for the Semantic Web. Journal of Biomedical Semantics, 2013 (4): 38. DOI: <a rel="biro:references" href="https://doi.org/10.1186/2041-1480-4-38"><span rev="cito:cites" resource="">https://doi.org/10.1186/2041-1480-4-38</span></a></p>
            </li>
            <li id="maswana2015" role="doc-biblioentry" about="#maswana2015" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Sayako Maswana, Toshiyuki Kanamaru, Akira Tajino (2015). Move analysis of research articles across five engineering fields: What they share and what they do not. Ampersand, 2: 1-11. DOI: <a rel="biro:references" href="https://doi.org/10.1016/j.amper.2014.12.002"><span rev="cito:cites" resource="">https://doi.org/10.1016/j.amper.2014.12.002</span></a></p>
            </li>
            <li id="montague1970" role="doc-biblioentry" about="#montague1970" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Richard Montague (1970). Universal grammar. Theoria, 36 (3): 373-398. DOI: <a rel="biro:references" href="https://doi.org/10.1111/j.1755-2567.1970.tb00434.x"><span rev="cito:cites" resource="">https://doi.org/10.1111/j.1755-2567.1970.tb00434.x</span></a></p>
            </li>
            <li id="moreau2013" role="doc-biblioentry" about="#moreau2013" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Luc Moreau, Paolo Missier (2013). PROV-DM: The PROV Data Model. W3C Recommendation 30 April 2013. <a rel="biro:references" href="http://www.w3.org/TR/prov-dm/"><span rev="cito:cites" resource="">http://www.w3.org/TR/prov-dm/</span></a></p>
            </li>
            <li id="noble2008" role="doc-biblioentry" about="#noble2008" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Denis Noble (2008). The Music of Life: Biology beyond genes. Oxford University Press. ISBN: 9780199228362. <a rel="biro:references" href="https://global.oup.com/academic/product/the-music-of-life-9780199228362"><span rev="cito:cites" resource="">https://global.oup.com/academic/product/the-music-of-life-9780199228362</span></a></p>
            </li>
            <li id="pelletier1994" role="doc-biblioentry" about="#pelletier1994" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Francis J. Pelletier (1994). The Principle of Semantic Compositionality. Topoi 13 (1): 11-24. DOI: <a rel="biro:references" href="https://doi.org/10.1007/BF00763644"><span rev="cito:cites" resource="">https://doi.org/10.1007/BF00763644</span></a></p>
            </li>
            <li id="peroni2016" role="doc-biblioentry" about="#peroni2016" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Silvio Peroni, Francesco Osborne, Angelo Di Iorio, Andrea Giovanni Nuzzolese, Francesco Poggi, Fabio Vitali, Enrico Motta (2016). Research Articles in Simplified HTML: a Web-first format for HTML-based scholarly articles. PeerJ PrePrints 4: e2513. DOI: <a rel="biro:references" href="https://doi.org/10.7287/peerj.preprints.2513"><span rev="cito:cites" resource="">https://doi.org/10.7287/peerj.preprints.2513</span></a></p>
            </li>
            <li id="peroni2012" role="doc-biblioentry" about="#peroni2012" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Silvio Peroni, David Shotton (2012). FaBiO and CiTO: Ontologies for describing bibliographic resources and citations. Web Semantics, 17: 33-43. DOI: <a rel="biro:references" href="https://doi.org/10.1016/j.websem.2012.08.001"><span rev="cito:cites" resource="">https://doi.org/10.1016/j.websem.2012.08.001</span></a></p>
            </li>
            <li id="sanderson2017" role="doc-biblioentry" about="#sanderson2017" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Robert Sanderson, Paolo Ciccarese, Benjamin Young (2017). Web Annotation Data Model. W3C Recommendation 23 February 2017. <a rel="biro:references" href="https://www.w3.org/TR/annotation-model/"><span rev="cito:cites" resource="">https://www.w3.org/TR/annotation-model/</span></a></p>
            </li>
            <li id="sateli2015" role="doc-biblioentry" about="#sateli2015" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Bahar Sateli​, René Witte (2015).​ Semantic representation of scientific literature: bringing claims, contributions and named entities onto the Linked Open Data cloud. PeerJ Computer Science: e37. DOI: <a rel="biro:references" href="https://doi.org/10.7717/peerj-cs.37"><span rev="cito:cites" resource="">https://doi.org/10.7717/peerj-cs.37</span></a></p>
            </li>
            <li id="shotton2009" role="doc-biblioentry" about="#shotton2009" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">David Shotton (2009). Semantic publishing: the coming revolution in scientific journal publishing. Learned Publishing, 22 (2): 85-94. DOI: <a rel="biro:references" href="https://doi.org/10.1087/2009202"><span rev="cito:cites" resource="">https://doi.org/10.1087/2009202</span></a></p>
            </li>
            <li id="shotton2009_2" role="doc-biblioentry" about="#shotton2009_2" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">David Shotton, Katie Portwin, Graham Klyne, Alistair Miles (2009). Adventures in Semantic Publishing: Exemplar Semantic Enhancements of a Research Article. PLoS Computational Biology, 5 (4). DOI: <a rel="biro:references" href="https://doi.org/10.1371/journal.pcbi.1000361"><span rev="cito:cites" resource="">https://doi.org/10.1371/journal.pcbi.1000361</span></a></p>
            </li>
            <li id="sperbergmcqueen2004" role="doc-biblioentry" about="#sperbergmcqueen2004" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Michael Sperberg-McQueen, Claus Huitfeldt (2004). GODDAG: A Data Structure for Overlapping Hierarchies. In Proceedings of the 5<sup>th</sup> International Workshop on Principles of Digital Document Processing (PODDP 2000): 139-160. DOI: <a rel="biro:references" href="https://doi.org/10.1007/978-3-540-39916-2_12"><span rev="cito:cites" resource="">https://doi.org/10.1007/978-3-540-39916-2_12</span></a></p>
            </li>
            <li id="taghva2006" role="doc-biblioentry" about="#taghva2006" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Kazem Taghva, Allen Condit, Julie Borsack (2006). Autotag: a tool for creating structured document collections from printed materials. In Proceedings of the 7th International Conference on Electronic Publishing (EP 2007): 420-431. DOI: <a rel="biro:references" href="https://doi.org/10.1007/BFb0053288"><span rev="cito:cites" resource="">https://doi.org/10.1007/BFb0053288</span></a></p>
            </li>
            <li id="tannier2005" role="doc-biblioentry" about="#tannier2005" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Xavier Tannier, Jean-Jacques Girardot, Mihaela Mathieu (2005). Classifying XML tags through “reading contexts”. In Proceedings of the 2005 ACM symposium on Document engineering (DocEng05): 143-145. DOI: <a rel="biro:references" href="https://doi.org/10.1145/1096601.1096638"><span rev="cito:cites" resource="">https://doi.org/10.1145/1096601.1096638</span></a></p>
            </li>
            <li id="teufel2006" role="doc-biblioentry" about="#teufel2006" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Simone Teufel, Advaith Siddharthan, Dan Tidhar (2006). Automatic classification of citation function. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006): 103-110. DOI: <a rel="biro:references" href="https://doi.org/10.3115/1610075.1610091"><span rev="cito:cites" resource="">https://doi.org/10.3115/1610075.1610091</span></a></p>
            </li>
            <li id="teiconsortium2016" role="doc-biblioentry" about="#teiconsortium2016" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Text Encoding Initiative Consortium (2016). TEI P5: Guidelines for Electronic Text Encoding and Interchange. <a rel="biro:references" href="http://www.tei-c.org/release/doc/tei-p5-doc/en/html/"><span rev="cito:cites" resource="">http://www.tei-c.org/release/doc/tei-p5-doc/en/html/</span></a> (last visited May 30, 2017)</p>
            </li>
            <li id="toulmin1958" role="doc-biblioentry" about="#toulmin1958" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Stephen Toulmin (1958). The uses of argument. Cambridge, Cambridge University Press. ISBN: 9780521827485. <a rel="biro:references" href="http://johnnywalters.weebly.com/uploads/1/3/3/5/13358288/toulmin-the-uses-of-argument_1.pdf"><span rev="cito:cites" resource="">http://johnnywalters.weebly.com/uploads/1/3/3/5/13358288/toulmin-the-uses-of-argument_1.pdf</span></a> (last visited May 30, 2017)</p>
            </li>
            <li id="vitali2005" role="doc-biblioentry" about="#vitali2015" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Fabio Vitali, Angelo Di Iorio, Daniele Gubellini (2005). Design patterns for document substructures. In Proceedings of the Extreme Markup Languages 2005. <a rel="biro:references" href="http://conferences.idealliance.org/extreme/html/2005/Vitali01/EML2005Vitali01.html"><span rev="cito:cites" resource="">http://conferences.idealliance.org/extreme/html/2005/Vitali01/EML2005Vitali01.html</span></a> (last visited May 30, 2017)</p>
            </li>
            <li id="walsh2010" role="doc-biblioentry" about="#walsh2010" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Norman Walsh (2010). DocBook 5: The Definitive Guide. Sebastopol, O'Reilly Media. ISBN: 9780596805029. <a rel="biro:references" href="http://tdg.docbook.org/tdg/5.0/docbook.html"><span rev="cito:cites" resource="">http://tdg.docbook.org/tdg/5.0/docbook.html</span></a> (last visited May 30, 2017)</p>
            </li>
            <li id="wilkinson2016" role="doc-biblioentry" about="#wilkinson2016" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Mark D. Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Appleton, Myles Axton, Arie Baak, Niklas Blomberg, Jan-Willem Boiten, Luiz Bonino da Silva Santos, Philip E. Bourne, Jildau Bouwman, Anthony J. Brookes, Tim Clark, Mercè Crosas, Ingrid Dillo, Olivier Dumon, Scott Edmunds, Chris T. Evelo, Richard Finkers, Alejandra Gonzalez-Beltran, Alasdair J.G. Gray, Paul Groth, Carole Goble, Jeffrey S. Grethe, Jaap Heringa, Peter A.C ’t Hoen, Rob Hooft, Tobias Kuhn, Ruben Kok, Joost Kok, Scott J. Lusher, Maryann E. Martone, Albert Mons, Abel L. Packer, Bengt Persson, Philippe Rocca-Serra, Marco Roos, Rene van Schaik, Susanna-Assunta Sansone, Erik Schultes, Thierry Sengstag, Ted Slater, George Strawn, Morris A. Swertz, Mark Thompson, Johan van der Lei, Erik van Mulligen, Jan Velterop, Andra Waagmeester, Peter Wittenburg, Katherine Wolstencroft, Jun Zhao, Barend Mons (2016). The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data 3. DOI: <a rel="biro:references" href="https://doi.org/10.1038/sdata.2016.18"><span rev="cito:cites" resource="">https://doi.org/10.1038/sdata.2016.18</span></a></p>
            </li>
            <li id="zou2007" role="doc-biblioentry" about="#zou2007" typeof="deo:BibliographicReference">
               <p property="c4o:hasContent">Jie Zou, Daniel Le, George R. Thoma (2007). Structure and Content Analysis for HTML Medical Articles: A Hidden Markov Model Approach. In Proceedings of the 2007 ACM symposium on Document engineering (DocEng 2007): 199-201. DOI: <a rel="biro:references" href="https://doi.org/10.1145/1284420.1284468"><span rev="cito:cites" resource="">https://doi.org/10.1145/1284420.1284468</span></a></p>
            </li>
         </ol>
      </section>
      <section id="footnotes" about="#footnotes" typeof="po:Container" role="doc-endnotes" rel="frbr:part">
         <section id="fred-languages" about="#fred-languages" typeof="doco:Footnote" role="doc-endnote">
            <p>Even if the official website of FRED claims it is able to <q>parse natural language text in 48 different languages and transform it to linked data</q>, empirical tests indicate that it has been trained appropriately only for English text. In fact, the other languages are not addressed directly, but rather they are handled first by translating non-English text into English (via the Microsoft Translation API) and then by applying the usual FRED workflow for transforming the English translation into Linked Data <span rel="frbr:part"><a id="gangemi2017-p2" about="#gangemi2017-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#gangemi2017"> </a></span>.</p>
         </section>
         <section id="semantic-lenses" about="#semantic-lenses" typeof="doco:Footnote" role="doc-endnote">
            <p>In the past, my colleagues and I have proposed a separation of the aspects characterizing any unit of scholarly communication (such as an article) into eight different containers we called <em>semantic lenses</em> <span rel="frbr:part"><a id="diiorio2014_2-p1" about="#diiorio2014_2-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2014_2"> </a></span>. Each lens is able to describe a particular semantic specification of an article, and it can concern either the description of the article content from different angles (e.g. structure, rhetoric, argumentation of such article), or contextual elements relating to the creation of a paper (e.g. research project, people contributions, publication venue).</p>
         </section>
         <section id="implementations" about="#implementations" typeof="doco:Footnote" role="doc-endnote">
            <p>In the following section only a brief introduction of the various implementations of CISE is provided, since I prefer to focus on the outcomes obtained by using such implementations by presenting some meaningful examples. Additional details about the theoretical foundations of these implementations and the precise explanation of all the algorithms can be found in <span rel="frbr:part"><a id="diiorio2014-p7" about="#diiorio2014-p7" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2014"> </a></span> and <span rel="frbr:part"><a id="diiorio2013-p5" about="#diiorio2013-p5" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#diiorio2013"> </a></span>.</p>
         </section>
         <section id="flat-structure" about="#flat-structure" typeof="doco:Footnote" role="doc-endnote">
            <p>In the particular example introduced, it would be possible, in principle, to reconstruct automatically the section-subsection containment by looking at the headings included in such a flat structure. This flat way of organising sections is adopted in existing markup languages for textual documents, such as LaTeX and ODT <span rel="frbr:part"><a id="odt2006-p1" about="#odt2006-p1" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#odt2006"> </a></span>.</p>
         </section>
         <section id="noble-thesis" about="#noble-thesis" typeof="doco:Footnote" role="doc-endnote">
            <p>In his book <span rel="frbr:part"><a id="noble2008-p2" about="#noble2008-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#noble2008"></a></span>, Noble claims that, if we regard complexity of a biological system as layered, the more complex layers show emergent properties that cannot be fully explained by the reductionist approach of looking at the simpler layers (e.g. <span rel="frbr:part"><a id="crick1966-p2" about="#crick1966-p2" typeof="c4o:InTextReferencePointer" rel="c4o:denotes" href="#crick1966"></a></span>). For example, while the message of DNA (higher layer) is encoded in the four types of nucleotide base (lower layer) that comprise it, it is not determined by them.</p>
         </section>
      </section>
   </body>
</html>
